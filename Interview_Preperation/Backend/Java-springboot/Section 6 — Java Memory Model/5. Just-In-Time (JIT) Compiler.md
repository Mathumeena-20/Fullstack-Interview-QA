# **1. What is JIT compiler?**

JIT = **Just-In-Time compiler**
It is part of JVM that **converts frequently executed bytecode into native machine code at runtime**.

Why?
✔ Native machine code runs MUCH faster than interpreting bytecode line by line.

JIT works during execution and applies optimizations such as:

* Method inlining
* Loop unrolling
* Dead code elimination
* Escape analysis
* Devirtualization

---

# **2. Difference between JIT and Interpreter**

| Feature      | Interpreter                    | JIT Compiler                      |
| ------------ | ------------------------------ | --------------------------------- |
| Output       | Executes bytecode line-by-line | Converts bytecode → machine code  |
| Speed        | Slower                         | Much faster                       |
| When runs    | Always                         | On hot methods (frequently used)  |
| Startup time | Fast                           | Slower (initial compilation cost) |
| Optimization | None                           | Many optimizations                |

Java uses **both**:

* Interpreter → fast startup
* JIT → optimize “hot” code over time

This gives Java both **good startup** + **high long-term performance**.

---

# **3. How does JIT improve performance?**

JIT performs multiple optimizations:

✔ **Method inlining** (remove method call overhead)
✔ **Escape analysis** → stack allocation
✔ **Loop optimization** (loop unrolling, induction variable elimination)
✔ **Dead code elimination**
✔ **Constant folding**
✔ **Devirtualization** (convert virtual → direct method call)
✔ **Register allocation**
✔ **Dynamic profiling** based optimization

After optimization → native machine code → extremely fast execution.

---

# **4. What is HotSpot JVM?**

HotSpot is the **most widely used JVM implementation** developed by Oracle.

Key features:

* Adaptive optimization (JIT + profiling)
* HotSpot = “optimize hot code”
* Garbage collectors (G1, ZGC, Parallel, etc.)
* Tiered compilation (C1/C2)
* Deoptimization support

HotSpot uses **runtime profiling to choose best optimizations**.

---

# **5. What is bytecode?**

Bytecode is the **intermediate platform-independent code** generated by Java compiler (`.class` files).

It is executed by:

* JVM Interpreter
* or compiled to machine code by JIT

Example bytecode (simplified):

```
0: iconst_5
1: istore_1
2: getstatic java/lang/System/out Ljava/io/PrintStream;
3: iload_1
4: invokevirtual java/io/PrintStream.println (I)V
```

---

# **6. What is method inlining?**

Inlining replaces a method call with the **method’s actual code**.

Example:

### Original:

```java
int add(int a, int b) { return a + b; }

int x = add(5, 10);
```

### After JIT inlining:

```
int x = 5 + 10;
```

Benefits:
✔ Fast execution
✔ Removes call overhead
✔ Enables further optimizations (constant folding, dead code removal)

Inlining is one of the **biggest JIT performance boosters**.

---

# **7. What is tiered compilation?**

Tiered compilation = JVM uses **both C1 (fast) and C2 (high-performance) compilers**.

Stages:

| Tier   | Compiler       | Purpose                                          |
| ------ | -------------- | ------------------------------------------------ |
| Tier 0 | Interpreter    | Fast startup                                     |
| Tier 1 | C1             | Quick compilation with light optimization        |
| Tier 2 | C1 + profiling | Collect method profiling data                    |
| Tier 3 | C2             | Highly optimized machine code using profile data |

This gives:
✔ Fast startup
✔ Maximum long-term optimization

Enabled by default in modern JVM:

```
-XX:+TieredCompilation
```

---

# **8. What is dynamic compilation?**

Dynamic compilation means the JVM:

✔ Compiles bytecode → native machine code **at runtime**
✔ Based on actual execution patterns
✔ Recompiles hot methods with better optimizations

The JVM **adapts** to the running program.

Example:

* If loop becomes hot → JVM optimizes it
* If branch usually goes one direction → apply branch prediction optimization

---

# **9. Difference between C1 and C2 compiler**

| Feature            | C1 (Client Compiler) | C2 (Server Compiler)   |
| ------------------ | -------------------- | ---------------------- |
| Goals              | Fast startup         | Peak performance       |
| Optimization level | Basic                | Aggressive             |
| Compilation speed  | Faster               | Slower                 |
| Uses profiling?    | Optional             | Yes, heavy profiling   |
| When used          | GUI apps, desktops   | Servers, microservices |

Modern JVM uses them together in tiered compilation.

---

# **10. What is profiling in JIT?**

JIT collects **runtime statistics** to optimize code.

Profiling collects information like:

* Method hotness
* Loop trip counts
* Branch probabilities
* Allocation patterns
* Virtual call targets
* Escape analysis info

Profiling allows JIT to perform **adaptive optimizations** like:
✔ inlining the most used methods
✔ eliminating unused branches
✔ optimizing hot loops
✔ promoting objects from heap to stack

Without profiling, C2 cannot optimize effectively.

---

# ⭐ Example showing JIT optimization in action

```java
public int sum(int n) {
    int total = 0;
    for(int i = 0; i < n; i++) {
        total += add(i, 1);
    }
    return total;
}

private int add(int a, int b) {
    return a + b;
}
```

JIT will:

1. Detect sum() as hot method
2. Inline add() → removes call overhead
3. Apply loop optimizations
4. Use registers for variables
5. Convert code to native machine code

Result: **Extremely fast execution**.

---

# ⭐ Final Interview Summary

| Topic               | Short Answer                                                 |
| ------------------- | ------------------------------------------------------------ |
| JIT                 | Compiles hot bytecode into native code                       |
| JIT vs Interpreter  | Interpreter = slow line-by-line; JIT = optimized native code |
| HotSpot JVM         | Adaptive optimization + GC + JIT profiling                   |
| Bytecode            | JVM-readable intermediate instruction                        |
| Inlining            | Inline method body → faster code                             |
| Tiered Compilation  | C1 + C2 for balance of speed + optimization                  |
| Dynamic Compilation | Optimization based on runtime behavior                       |
| C1 vs C2            | C1 = fast compile; C2 = best optimization                    |
| Profiling           | HotSpot collects runtime data for optimization               |

---

